# HMA Compliance & Security Stack
# CISO Assistant (GRC) + Wazuh (SIEM) for ISO 27001, SOC 2, GDPR, CCPA compliance
# Integrates with existing hma-infra Docker stack

services:
  # ============================================================================
  # CISO ASSISTANT - GRC/ISMS/COMPLIANCE PLATFORM
  # ============================================================================
  
  # CISO Assistant Backend (Django/Python)
  hma-ciso-backend:
    image: ghcr.io/intuitem/ciso-assistant-community/backend:latest
    container_name: hma_ciso_backend
    restart: unless-stopped
    environment:
      # Database connection (shared PostgreSQL)  
      DB_ENGINE: django.db.backends.postgresql
      POSTGRES_NAME: ciso_assistant
      POSTGRES_USER: ciso_admin
      POSTGRES_PASSWORD: ${CISO_DB_PASSWORD:-change_me_ciso_db_pass}
      DB_HOST: postgres
      POSTGRES_PORT: 5432
      
      # Django configuration
      ALLOWED_HOSTS: hma-ciso-backend,hma_ciso_backend,localhost,127.0.0.1
      CISO_ASSISTANT_URL: https://localhost:8443
      DJANGO_SECRET_KEY: ${CISO_DJANGO_SECRET:-change_me_to_50_char_random_string}
      DJANGO_DEBUG: "False"
      AUTH_TOKEN_TTL: 7200
      
      # S3/MinIO for evidence storage
      AWS_ACCESS_KEY_ID: ${MINIO_USER:-minioadmin}
      AWS_SECRET_ACCESS_KEY: ${MINIO_PASSWORD:-minioadmin}
      AWS_S3_ENDPOINT_URL: http://minio:9000
      AWS_STORAGE_BUCKET_NAME: hma-compliance-evidence
      AWS_S3_REGION_NAME: us-east-1
      AWS_DEFAULT_REGION: us-east-1
      AWS_S3_USE_SSL: "false"
      
      # Email Configuration (Hostinger SMTP - Port 587 with STARTTLS)
      # Using port 587 with STARTTLS because Django doesn't support EMAIL_USE_SSL for port 465
      # Using hostname for proper SSL certificate validation
      EMAIL_HOST: ${SMTP_HOST}
      EMAIL_HOST_USER: ${SMTP_USER}
      EMAIL_HOST_PASSWORD: ${SMTP_PASSWORD}
      EMAIL_PORT: 587
      EMAIL_USE_TLS: "True"
      DEFAULT_FROM_EMAIL: ${SMTP_FROM}
      EMAIL_TIMEOUT: 30
      
      # Redis for background tasks (use Redis instead of SQLite)
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD:-development_redis}
      
      # Huey task queue configuration (force Redis instead of SQLite)
      HUEY_STORAGE: redis
      HUEY_HOST: redis
      HUEY_PORT: 6379
      HUEY_PASSWORD: ${REDIS_PASSWORD:-development_redis}
      HUEY_FILE_PATH: /app/db/huey.db
      
    volumes:
      - ciso_media:/app/media
      - ciso_static:/app/static
      - ./ciso-data/db:/app/db
    extra_hosts:
      # Force IPv4 resolution for smtp.hostinger.com (container has IPv6 DNS but no IPv6 route)
      - "smtp.hostinger.com:172.65.255.143"
    networks:
      - hma-network
    healthcheck:
      test: ["CMD", "/code/.venv/bin/python", "manage.py", "check", "--database", "default"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # CISO Assistant Frontend (SvelteKit/Node.js)
  hma-ciso-frontend:
    image: ghcr.io/intuitem/ciso-assistant-community/frontend:latest
    container_name: hma_ciso_frontend
    restart: unless-stopped
    environment:
      PUBLIC_BACKEND_API_URL: http://hma-ciso-backend:8000/api
      ORIGIN: https://localhost:8443
      PROTOCOL_HEADER: x-forwarded-proto
      HOST_HEADER: x-forwarded-host
    networks:
      - hma-network
    healthcheck:
      test: ["CMD-SHELL", "node -e \"fetch('http://localhost:3000').then(() => process.exit(0)).catch(() => process.exit(1))\""]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # CISO Assistant Task Queue (Huey worker for background jobs)
  hma-ciso-worker:
    image: ghcr.io/intuitem/ciso-assistant-community/backend:latest
    container_name: hma_ciso_worker
    restart: unless-stopped
    entrypoint: ["/bin/bash", "/scripts/run-ciso-worker.sh"]
    environment:
      # Same environment as backend
      DB_ENGINE: django.db.backends.postgresql
      POSTGRES_NAME: ciso_assistant
      POSTGRES_USER: ciso_admin
      POSTGRES_PASSWORD: ${CISO_DB_PASSWORD:-change_me_ciso_db_pass}
      POSTGRES_HOST: postgres
      DB_HOST: postgres  # Also needed by start script
      POSTGRES_PORT: 5432
      DJANGO_SECRET_KEY: ${CISO_DJANGO_SECRET:-change_me_to_50_char_random_string}
      DJANGO_DEBUG: "False"
      AWS_ACCESS_KEY_ID: ${MINIO_USER:-minioadmin}
      AWS_SECRET_ACCESS_KEY: ${MINIO_PASSWORD:-minioadmin}
      AWS_S3_ENDPOINT_URL: http://minio:9000
      AWS_STORAGE_BUCKET_NAME: hma-compliance-evidence
      AWS_S3_USE_SSL: "false"
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD:-development_redis}
      HUEY_FILE_PATH: /app/db/huey.db  # Explicitly set SQLite path
      
      # MinIO S3 Configuration for evidence collection
      AWS_S3_REGION_NAME: us-east-1
      AWS_DEFAULT_REGION: us-east-1
      
    volumes:
      - ciso_media:/app/media
      - ./ciso-data/db:/app/db  # SQLite Huey database
      - ./scripts/run-ciso-worker.sh:/scripts/run-ciso-worker.sh:ro
      - ./ciso-collectors:/app/tasks/collectors:ro  # Evidence collectors
      - /var/run/docker.sock:/var/run/docker.sock:ro  # Docker API access for inventory
    networks:
      - hma-network
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # ============================================================================
  # ELASTIC SECURITY - SIEM, SECURITY MONITORING & THREAT DETECTION
  # ============================================================================

  # Elasticsearch - Search and analytics engine
  hma-elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.3
    container_name: hma_elasticsearch
    restart: unless-stopped
    hostname: hma-elasticsearch
    environment:
      # [20251108-ELASTIC-001] Single-node cluster for development
      discovery.type: single-node
      cluster.name: hma-elastic-cluster
      node.name: hma-es-node-1
      
      # [20251108-ELASTIC-002] Security settings (basic auth, no TLS for dev)
      xpack.security.enabled: true
      xpack.security.enrollment.enabled: true
      xpack.security.http.ssl.enabled: false
      xpack.security.transport.ssl.enabled: false
      
      # Elastic password
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD:-HMA_Elastic_Dev_Pass_2025!}
      
      # Memory settings
      ES_JAVA_OPTS: "-Xms2g -Xmx2g"
      bootstrap.memory_lock: true
      
      # Performance
      indices.query.bool.max_clause_count: 8192
    ports:
      - "9200:9200"      # HTTP API
      - "9300:9300"      # Transport
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
      - elasticsearch_logs:/usr/share/elasticsearch/logs
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    networks:
      - hma-network
    healthcheck:
      test: ["CMD-SHELL", "curl -u elastic:${ELASTIC_PASSWORD:-HMA_Elastic_Dev_Pass_2025!} -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G

  # Kibana - Web UI for Elasticsearch and Security features
  hma-kibana:
    image: docker.elastic.co/kibana/kibana:8.15.3
    container_name: hma_kibana
    restart: unless-stopped
    hostname: hma-kibana
    environment:
      # [20251108-ELASTIC-003] Elasticsearch connection
      ELASTICSEARCH_HOSTS: '["http://hma-elasticsearch:9200"]'
      # [20251108-ELASTIC-006] Use service account token instead of elastic user
      ELASTICSEARCH_SERVICEACCOUNTTOKEN: ${KIBANA_SERVICE_TOKEN:-AAEAAWVsYXN0aWMva2liYW5hL2tpYmFuYS10b2tlbjpVZDNjMExKQVNZbUNDWkdxLWlpek5R}
      
      # Kibana configuration
      SERVER_NAME: hma-kibana
      SERVER_HOST: 0.0.0.0
      SERVER_PORT: 5601
      
      # [20251108-ELASTIC-004] Security features enabled
      XPACK_SECURITY_ENABLED: true
      XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY: ${KIBANA_ENCRYPTION_KEY:-a7e52c1b8f3d9e4a6b2c8d5f1e3a7b9c}
      
      # Monitoring
      XPACK_MONITORING_UI_CONTAINER_ELASTICSEARCH_ENABLED: true
    ports:
      - "5601:5601"
    volumes:
      - kibana_data:/usr/share/kibana/data
    networks:
      - hma-network
    depends_on:
      - hma-elasticsearch
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5601/api/status || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

  # APM Server - Application Performance Monitoring
  hma-apm-server:
    image: docker.elastic.co/apm/apm-server:8.15.3
    container_name: hma_apm_server
    restart: unless-stopped
    hostname: hma-apm-server
    command: >
      apm-server -e
        -E output.elasticsearch.hosts=["http://hma-elasticsearch:9200"]
        -E output.elasticsearch.username=elastic
        -E output.elasticsearch.password=${ELASTIC_PASSWORD:-HMA_Elastic_Dev_Pass_2025!}
        -E apm-server.kibana.enabled=true
        -E apm-server.kibana.host=hma-kibana:5601
        -E apm-server.host=0.0.0.0:8200
        -E apm-server.rum.enabled=true
        -E apm-server.rum.allow_origins=['*']
        -E apm-server.secret_token=${APM_SECRET_TOKEN:-HMA_APM_Secret_2025}
        -E monitoring.enabled=true
    ports:
      - "8201:8200"
    volumes:
      - apm_data:/usr/share/apm-server/data
    networks:
      - hma-network
    depends_on:
      - hma-elasticsearch
      - hma-kibana
    healthcheck:
      test: ["CMD-SHELL", "pgrep -f apm-server || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # Fleet Server - Centralized management for Elastic Agents (OPTIONAL)
  # Uncomment to enable centralized agent management
  # hma-fleet-server:
  #   image: docker.elastic.co/beats/elastic-agent:8.15.3
  #   container_name: hma_fleet_server
  #   restart: unless-stopped
  #   hostname: hma-fleet-server
  #   profiles: ["fleet"]  # Only start with --profile fleet
  #   environment:
  #     # [20251108-ELASTIC-005] Fleet server mode
  #     FLEET_SERVER_ENABLE: "1"
  #     FLEET_SERVER_ELASTICSEARCH_HOST: http://hma-elasticsearch:9200
  #     FLEET_SERVER_ELASTICSEARCH_USERNAME: elastic
  #     FLEET_SERVER_ELASTICSEARCH_PASSWORD: ${ELASTIC_PASSWORD:-HMA_Elastic_Dev_Pass_2025!}
  #     FLEET_SERVER_SERVICE_TOKEN: ${FLEET_SERVER_SERVICE_TOKEN}
  #     FLEET_SERVER_POLICY_ID: fleet-server-policy
  #     FLEET_SERVER_PORT: 8220
  #     FLEET_SERVER_HOST: 0.0.0.0
  #     FLEET_SERVER_INSECURE_HTTP: "1"
  #     
  #     # Kibana connection
  #     KIBANA_FLEET_HOST: http://hma-kibana:5601
  #     KIBANA_FLEET_USERNAME: elastic
  #     KIBANA_FLEET_PASSWORD: ${ELASTIC_PASSWORD:-HMA_Elastic_Dev_Pass_2025!}
  #   ports:
  #     - "8220:8220"
  #   volumes:
  #     - fleet_data:/usr/share/elastic-agent/state
  #   networks:
  #     - hma-network
  #   depends_on:
  #     - hma-elasticsearch
  #     - hma-kibana
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 1G
  #       reservations:
  #         memory: 512M

  # ============================================================================
  # REVERSE PROXY - TLS TERMINATION & ROUTING
  # ============================================================================

  # Caddy - Automatic HTTPS with Let's Encrypt
  hma-caddy:
    image: caddy:2-alpine
    container_name: hma_caddy
    restart: unless-stopped
    ports:
      - "8443:443"       # HTTPS for CISO Assistant
      - "8444:8444"      # HTTPS for Wazuh Dashboard
    volumes:
      - ./caddy/Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy_data:/data
      - caddy_config:/config
    networks:
      - hma-network
    healthcheck:
      test: ["CMD", "pidof", "caddy"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M

  # ============================================================================
  # PROMETHEUS EXPORTERS - METRICS FOR MONITORING
  # ============================================================================

  # Note: Elasticsearch metrics can be scraped from /_prometheus/metrics endpoint
  # Kibana provides metrics at /api/status

volumes:
  # CISO Assistant volumes
  ciso_media:
    driver: local
  ciso_static:
    driver: local
  ciso_db:
    driver: local
  
  # Elastic Stack volumes
  elasticsearch_data:
    driver: local
  elasticsearch_logs:
    driver: local
  kibana_data:
    driver: local
  apm_data:
    driver: local
  fleet_data:
    driver: local
  
  # Caddy volumes
  caddy_data:
    driver: local
  caddy_config:
    driver: local

networks:
  hma-network:
    external: true

# ============================================================================
# DEPLOYMENT INSTRUCTIONS
# ============================================================================
#
# 1. Set kernel parameter for Elasticsearch:
#    sudo sysctl -w vm.max_map_count=262144
#    echo "vm.max_map_count=262144" | sudo tee -a /etc/sysctl.conf
#
# 2. Create environment file (.env.compliance):
#    cp .env.compliance.example .env.compliance
#    # Edit and set secure passwords
#
# 3. Create PostgreSQL databases (see scripts/init-compliance-dbs.sh):
#    docker exec hma_postgres psql -U hma_admin -d hma_academy -c "CREATE DATABASE ciso_assistant;"
#    docker exec hma_postgres psql -U hma_admin -d hma_academy -c "CREATE USER ciso_admin WITH PASSWORD 'secure_password';"
#    docker exec hma_postgres psql -U hma_admin -d hma_academy -c "GRANT ALL PRIVILEGES ON DATABASE ciso_assistant TO ciso_admin;"
#
# 4. Create MinIO bucket for evidence:
#    docker exec hma_minio mc mb /data/hma-compliance-evidence
#
# 5. Create Caddy configuration:
#    mkdir -p caddy
#    # Create Caddyfile (see caddy/Caddyfile.example)
#
# 6. Create Wazuh configuration directories:
#    mkdir -p wazuh-config/rules wazuh-config/decoders
#
# 7. Deploy compliance stack:
#    docker compose -f docker-compose.compliance.yml up -d
#
# 8. Check service health:
#    docker compose -f docker-compose.compliance.yml ps
#    docker compose -f docker-compose.compliance.yml logs -f
#
# 9. Access services:
#    CISO Assistant: https://localhost:8443
#    Wazuh Dashboard: https://localhost:8444
#    Wazuh API: https://localhost:55000
#
# 10. Initialize CISO Assistant:
#     docker exec hma_ciso_backend python manage.py migrate
#     docker exec hma_ciso_backend python manage.py createsuperuser
#     docker exec hma_ciso_backend python manage.py loaddata frameworks
#
# ============================================================================
